# Phase 1 Foundation - Quick Start Guide

## ğŸ‰ What's Been Built

Phase 1 of the CaRMS Residency Program Data Platform is complete! This provides a solid foundation with:

- **Production-ready project structure** following best practices
- **Data warehouse schema** with 6 SQLModel tables (star schema design)
- **Basic Dagster ETL pipeline** with 4 raw data ingestion assets
- **FastAPI REST API** with health checks and auto-documentation
- **Docker containerization** for PostgreSQL, Dagster, and FastAPI
- **Testing infrastructure** with 5 passing tests
- **Comprehensive documentation** and setup scripts

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

1. **Start all services:**
   ```bash
   cd docker
   docker-compose up -d
   ```

2. **Access the services:**
   - Dagster UI: http://localhost:3000
   - FastAPI Docs: http://localhost:8000/docs
   - PostgreSQL: localhost:5432

3. **Initialize the database:**
   ```bash
   # Wait for PostgreSQL to be ready (about 10 seconds)
   source .venv/bin/activate
   python scripts/init_db.py
   ```

### Option 2: Local Development

1. **Set up Python environment:**
   ```bash
   # Create and activate virtual environment
   uv venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   
   # Install dependencies
   uv pip install -e ".[dev]"
   ```

2. **Start PostgreSQL** (via Docker or local installation)

3. **Run services locally:**
   ```bash
   # Terminal 1: Dagster
   dagster dev -m src.dagster_project
   
   # Terminal 2: FastAPI
   uvicorn src.api.main:app --reload
   ```

## ğŸ“‚ Project Structure

```
szw/
â”œâ”€â”€ src/                        # Main source code
â”‚   â”œâ”€â”€ models/                 # SQLModel database schemas
â”‚   â”‚   â”œâ”€â”€ base.py            # Base models with timestamps
â”‚   â”‚   â”œâ”€â”€ university.py      # University dimension
â”‚   â”‚   â”œâ”€â”€ specialty.py       # Specialty dimension
â”‚   â”‚   â”œâ”€â”€ program.py         # Program fact table
â”‚   â”‚   â”œâ”€â”€ requirement.py     # Requirements dimension
â”‚   â”‚   â”œâ”€â”€ training_site.py   # Training sites dimension
â”‚   â”‚   â””â”€â”€ selection_criteria.py
â”‚   â”œâ”€â”€ dagster_project/       # ETL pipeline
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”‚   â””â”€â”€ raw_data.py    # Raw data ingestion
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ __init__.py    # Database resource
â”‚   â”œâ”€â”€ api/                   # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py           # App with health endpoints
â”‚   â”‚   â””â”€â”€ routes/           # Route modules (Phase 2)
â”‚   â”œâ”€â”€ utils/                # Shared utilities
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â”‚   â””â”€â”€ database.py       # Database utilities
â”‚   â”œâ”€â”€ matching/             # Match simulation (Phase 3)
â”‚   â””â”€â”€ reporting/            # Reporting framework (Phase 3)
â”œâ”€â”€ tests/                    # Test suite
â”‚   â”œâ”€â”€ conftest.py          # Pytest fixtures
â”‚   â”œâ”€â”€ test_models.py       # Model tests (5 passing)
â”‚   â””â”€â”€ test_api.py          # API tests
â”œâ”€â”€ docker/                   # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.dagster
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ init-db.sql
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ init_db.py           # Database initialization
â”‚   â”œâ”€â”€ verify.py            # Installation verification
â”‚   â””â”€â”€ setup.sh             # Quick setup script
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.md      # System architecture
â”œâ”€â”€ pyproject.toml           # Project configuration
â”œâ”€â”€ README.md                # Main documentation
â””â”€â”€ PHASE1_COMPLETE.md       # This file
```

## ğŸ§ª Verify Installation

```bash
source .venv/bin/activate
python scripts/verify.py
```

This checks:
- âœ… All Python packages installed
- âœ… Models can be imported
- âœ… Configuration loads correctly
- âœ… Dagster definitions valid
- âœ… FastAPI app loads
- âš ï¸  Database connection (needs Docker)
- âš ï¸  Data files (not in repo)

## ğŸ”§ Key Files

### Configuration
- `.env` - Environment variables (create from `.env.example`)
- `pyproject.toml` - Dependencies and project metadata

### Database Models (Star Schema)
All models in `src/models/`:
- **Dimensions**: Universities, Specialties, Requirements, Training Sites, Selection Criteria
- **Facts**: Programs (main fact table)
- **Features**: Audit columns, soft deletes, proper relationships

### ETL Assets
Current raw data assets in `src/dagster_project/assets/raw_data.py`:
- Load JSON program descriptions
- Load CSV cross-sectional data
- Load Excel master data
- Load discipline data

### API Endpoints
Current endpoints in `src/api/main.py`:
- `GET /` - API information
- `GET /health` - Health check

## ğŸ“Š Database Schema

### Dimension Tables
```
dim_universities       - University information
dim_specialties       - Medical specialties with hierarchy
dim_requirements      - Program eligibility requirements
dim_training_sites    - Clinical training locations
dim_selection_criteria - How programs evaluate candidates
```

### Fact Table
```
fact_programs         - Core residency program information
  â”œâ”€> university_id   (FK to dim_universities)
  â””â”€> specialty_id    (FK to dim_specialties)
```

All tables include:
- `id` (primary key)
- `created_at`, `updated_at` (audit columns)
- `is_deleted`, `deleted_at` (soft delete support)

## ğŸ§ª Running Tests

```bash
# All tests
pytest

# Specific test file
pytest tests/test_models.py -v

# With coverage
pytest --cov=src tests/

# Current status: 5/5 tests passing âœ…
```

## ğŸ› ï¸ Development Commands

### Database
```bash
# Initialize database
python scripts/init_db.py

# Connect to PostgreSQL
docker exec -it carms-postgres psql -U carms -d carms
```

### Code Quality
```bash
# Format code
black src/ tests/

# Lint code
ruff src/ tests/

# Type checking
mypy src/
```

### Docker
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Rebuild
docker-compose up --build
```

## ğŸ“š Next: Phase 2

Phase 2 will implement:

1. **Complete ETL Pipeline**
   - Staging layer with data cleaning and validation
   - Serving layer to populate warehouse tables
   - Analytics layer for derived metrics
   - Comprehensive data quality checks

2. **Full API Implementation**
   - Program CRUD endpoints with filters
   - Analytics endpoints for insights
   - Proper request/response models
   - Pagination and sorting

3. **Expanded Testing**
   - Integration tests for ETL pipeline
   - API endpoint tests with test database
   - Data quality test cases

## ğŸ¯ Success Metrics - Phase 1

### Completed âœ…
- [x] Clean project structure
- [x] 6 SQLModel tables with relationships
- [x] 4 Dagster raw data assets
- [x] Basic FastAPI with 2 endpoints
- [x] Docker setup with 3 services
- [x] 5 passing tests
- [x] Comprehensive documentation
- [x] Type hints throughout
- [x] Configuration management
- [x] Database utilities

### Phase 2 Goals
- [ ] 10+ Dagster assets (staging + serving)
- [ ] 10+ API endpoints
- [ ] 20+ tests with 80% coverage
- [ ] Data quality checks
- [ ] Full ETL pipeline functional

## ğŸ’¡ Tips

1. **Use Docker for simplicity** - Everything just works
2. **Check logs** if something fails - `docker-compose logs -f`
3. **Verify installation** - Run `python scripts/verify.py`
4. **Read the docs** - Check `docs/architecture.md` for design details
5. **Run tests** - Ensure everything works after changes

## ğŸ› Troubleshooting

### Database connection failed
```bash
# Make sure PostgreSQL is running
docker-compose ps

# Restart if needed
docker-compose restart postgres

# Check logs
docker-compose logs postgres
```

### Import errors
```bash
# Reinstall dependencies
source .venv/bin/activate
uv pip install -e ".[dev]"
```

### Port already in use
```bash
# Check what's using the port
lsof -i :5432  # PostgreSQL
lsof -i :3000  # Dagster
lsof -i :8000  # FastAPI

# Change port in docker-compose.yml if needed
```

## ğŸ“ Support

- Check `README.md` for detailed setup instructions
- Review `docs/architecture.md` for design decisions
- Run `python scripts/verify.py` to diagnose issues
- Check Docker logs: `docker-compose logs -f [service]`

---

**Phase 1 is complete and ready for Phase 2 development!** ğŸ‰

The foundation is solid, well-tested, and follows production best practices.
